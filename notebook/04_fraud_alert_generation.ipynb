{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee5df745-4d25-442f-8ca3-a2f6189ec643",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 04_alert_generation.py\n",
    "from datetime import datetime, date\n",
    "from pyspark.sql.functions import col, lit, current_timestamp\n",
    "from pyspark.sql.types import StructType, StructField, BooleanType, TimestampType, IntegerType\n",
    "\n",
    "def send_fraud_alert_email(alert_data, ml_anomalies_count):\n",
    "    critical_count = alert_data.count()\n",
    "    \n",
    "    if critical_count > 0:\n",
    "        subject = f\"ðŸš¨ MediSure Fraud Alert: {critical_count} Critical Cases Detected\"\n",
    "        message = f\"\"\"\n",
    "        <h3>Critical Fraud Alerts - {date.today()}</h3>\n",
    "        <p>Number of critical alerts: <strong>{critical_count}</strong></p>\n",
    "        <p>ML Anomalies Detected: <strong>{ml_anomalies_count}</strong></p>\n",
    "        <h4>Top 5 Critical Cases:</h4>\n",
    "        <table border='1'>\n",
    "        <tr>\n",
    "            <th>Claim ID</th>\n",
    "            <th>Member</th>\n",
    "            <th>Provider</th>\n",
    "            <th>Amount</th>\n",
    "            <th>Fraud Score</th>\n",
    "            <th>Reason</th>\n",
    "        </tr>\n",
    "        \"\"\"\n",
    "        \n",
    "        for row in alert_data.limit(5).collect():\n",
    "            message += f\"\"\"\n",
    "            <tr>\n",
    "                <td>{row.claim_id}</td>\n",
    "                <td>{row.first_name or 'Unknown'} {row.last_name or ''}</td>\n",
    "                <td>{row.provider_name or 'Unknown Provider'}</td>\n",
    "                <td>${float(row.claim_amount or 0.0):,.2f}</td>\n",
    "                <td>{float(getattr(row, 'enhanced_fraud_score', 0.0)):.2f}</td>\n",
    "                <td>{row.alert_reason or 'Unknown'}</td>\n",
    "            </tr>\n",
    "            \"\"\"\n",
    "        \n",
    "        message += \"</table>\"\n",
    "        \n",
    "        print(f\"Would send email with subject: {subject}\")\n",
    "        print(f\"To: icon.montalbar@gmail.com\")\n",
    "        print(f\"Body: {message}\")\n",
    "        \n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*60)\n",
    "    print(\"ALERT GENERATION STARTED\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # =====================================================\n",
    "    # 1. Validate input and read decision\n",
    "    # =====================================================\n",
    "    try:\n",
    "        decision_df = spark.table(\"medisure_jen.temp.fraud_decision\")\n",
    "        decision = decision_df.first() if decision_df.count() > 0 else None\n",
    "        \n",
    "        if not decision:\n",
    "            print(\"No decision data found. Creating default no-fraud scenario.\")\n",
    "            # Create default decision\n",
    "            schema = StructType([\n",
    "                StructField(\"has_fraud\", BooleanType(), True),\n",
    "                StructField(\"critical_count\", IntegerType(), True),\n",
    "                StructField(\"ml_count\", IntegerType(), True)\n",
    "            ])\n",
    "            decision_df = spark.createDataFrame([(False, 0, 0)], schema)\n",
    "            decision = decision_df.first()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading decision table: {e}. Assuming no fraud.\")\n",
    "        schema = StructType([\n",
    "            StructField(\"has_fraud\", BooleanType(), True),\n",
    "            StructField(\"critical_count\", IntegerType(), True),\n",
    "            StructField(\"ml_count\", IntegerType(), True)\n",
    "        ])\n",
    "        decision_df = spark.createDataFrame([(False, 0, 0)], schema)\n",
    "        decision = decision_df.first()\n",
    "    \n",
    "    print(f\"Decision: Fraud detected = {decision.has_fraud}\")\n",
    "    print(f\"Critical alerts: {decision.critical_count}, ML anomalies: {decision.ml_count}\")\n",
    "    \n",
    "    # =====================================================\n",
    "    # 2. Handle FRAUD DETECTED path\n",
    "    # =====================================================\n",
    "    if decision and decision.has_fraud:\n",
    "        print(\"ðŸš¨ FRAUD DETECTED - Generating alerts and compliance records\")\n",
    "        \n",
    "        try:\n",
    "            # Read detected alerts\n",
    "            critical_alerts = spark.table(\"medisure_jen.temp.critical_alerts\")\n",
    "            ml_anomalies = spark.table(\"medisure_jen.temp.ml_anomalies\")\n",
    "            \n",
    "            print(f\"Processing {critical_alerts.count()} critical alerts\")\n",
    "            print(f\"Processing {ml_anomalies.count()} ML anomalies\")\n",
    "            \n",
    "            # Display sample for monitoring\n",
    "            if critical_alerts.count() > 0:\n",
    "                print(\"Sample critical alerts:\")\n",
    "                display(critical_alerts.select(\"claim_id\", \"claim_amount\", \"enhanced_fraud_score\", \"alert_severity\").limit(5))\n",
    "            \n",
    "            # Send email alerts\n",
    "            email_sent = send_fraud_alert_email(critical_alerts, ml_anomalies.count())\n",
    "            \n",
    "            # Create operational output\n",
    "            operational_output = critical_alerts.withColumn(\"alert_type\", lit(\"fraud_detected\")) \\\n",
    "                                               .withColumn(\"processing_timestamp\", current_timestamp())\n",
    "            \n",
    "            # Save operational data\n",
    "            operational_output.write.mode(\"overwrite\").saveAsTable(\"medisure_jen.temp.alert_true_fraud_detected\")\n",
    "            \n",
    "            # ðŸš¨ CRITICAL: Save restricted view for compliance team\n",
    "            print(\"Creating fraud_alerts_restricted table for compliance...\")\n",
    "            spark.sql(\"\"\"\n",
    "            CREATE OR REPLACE TABLE medisure_jen.audit.fraud_alerts_restricted\n",
    "            AS SELECT \n",
    "              claim_id, provider_id, claim_amount, alert_severity,\n",
    "              enhanced_fraud_score, alert_reason,\n",
    "              CASE \n",
    "                WHEN current_user() LIKE '%compliance%' THEN member_id\n",
    "                ELSE 'REDACTED'\n",
    "              END as member_id,\n",
    "              alert_timestamp,\n",
    "              current_timestamp() as restricted_view_created\n",
    "            FROM medisure_jen.temp.critical_alerts\n",
    "            \"\"\")\n",
    "            print(\"âœ… fraud_alerts_restricted table created successfully!\")\n",
    "            \n",
    "            # ðŸš¨ CRITICAL: Save ML anomalies for audit\n",
    "            if ml_anomalies.count() > 0:\n",
    "                print(\"Saving ML anomalies for audit...\")\n",
    "                ml_anomalies.write.mode(\"overwrite\") \\\n",
    "                    .option(\"mergeSchema\", \"true\") \\\n",
    "                    .saveAsTable(\"medisure_jen.audit.ml_anomalies_daily\")\n",
    "                print(\"âœ… ML anomalies saved for audit\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing fraud detected path: {e}\")\n",
    "            email_sent = False\n",
    "    \n",
    "    # =====================================================\n",
    "    # 3. Handle NO FRAUD path\n",
    "    # =====================================================\n",
    "    else:\n",
    "        print(\"âœ… NO FRAUD DETECTED - Generating audit records for clean transactions\")\n",
    "        \n",
    "        # Create audit record for clean day\n",
    "        false_path_output = decision_df.withColumn(\"alert_type\", lit(\"no_fraud_detected\")) \\\n",
    "                                      .withColumn(\"processing_timestamp\", current_timestamp())\n",
    "        \n",
    "        # Save audit data\n",
    "        false_path_output.write.mode(\"overwrite\").saveAsTable(\"medisure_jen.temp.alert_false_no_fraud\")\n",
    "        email_sent = False\n",
    "    \n",
    "    # =====================================================\n",
    "    # 4. Save email status for audit\n",
    "    # =====================================================\n",
    "    email_status = spark.createDataFrame([(email_sent,)], [\"email_sent\"])\n",
    "    email_status.write.mode(\"overwrite\").saveAsTable(\"medisure_jen.temp.email_status\")\n",
    "    \n",
    "    # =====================================================\n",
    "    # 5. Final summary\n",
    "    # =====================================================\n",
    "    print(\"=\"*60)\n",
    "    print(\"ALERT GENERATION COMPLETED\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Fraud Detected: {decision.has_fraud if decision else False}\")\n",
    "    print(f\"Email Sent: {email_sent}\")\n",
    "    print(f\"Critical Alerts Processed: {decision.critical_count if decision else 0}\")\n",
    "    print(f\"ML Anomalies Processed: {decision.ml_count if decision else 0}\")\n",
    "    \n",
    "    if decision and decision.has_fraud:\n",
    "        print(\"ðŸ“‹ Output: fraud_alerts_restricted, ml_anomalies_daily, alert_true_fraud_detected\")\n",
    "    else:\n",
    "        print(\"ðŸ“‹ Output: alert_false_no_fraud (audit record)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Execute main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_fraud_alert_generation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
