{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c5be3d3-4bd8-4b40-8766-e8bb611ace8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#03_fraud_conditional_routing notebook\n",
    "# Detection Flagging and Conditional Routing\n",
    "from pyspark.sql.functions import col, lit\n",
    "from pyspark.sql.types import StructType, StructField, BooleanType, IntegerType, TimestampType, StringType, FloatType\n",
    "from datetime import datetime\n",
    "\n",
    "def main():\n",
    "    # =====================================================\n",
    "    # 1. Validate input tables exist and have data\n",
    "    # =====================================================\n",
    "    print(\"Starting fraud conditional routing...\")\n",
    "    \n",
    "    # Check if temp VIEWS exist (not tables)\n",
    "    critical_alerts_exists = spark.catalog.tableExists(\"critical_alerts_temp\")\n",
    "    ml_anomalies_exists = spark.catalog.tableExists(\"ml_anomalies_temp\")\n",
    "    \n",
    "    # =====================================================\n",
    "    # 2. Read and count alerts with validation\n",
    "    # =====================================================\n",
    "    try:\n",
    "        if critical_alerts_exists:\n",
    "            critical_alerts = spark.table(\"critical_alerts_temp\")\n",
    "            critical_count = critical_alerts.count()\n",
    "        else:\n",
    "            print(\"No critical alerts found - creating empty dataframe\")\n",
    "            schema = StructType([\n",
    "                StructField(\"claim_id\", StringType(), True),\n",
    "                StructField(\"enhanced_fraud_score\", FloatType(), True),\n",
    "                StructField(\"alert_severity\", StringType(), True),\n",
    "                StructField(\"claim_amount\", FloatType(), True)\n",
    "            ])\n",
    "            critical_alerts = spark.createDataFrame([], schema)\n",
    "            critical_count = 0\n",
    "        \n",
    "        print(f\"Critical alerts analysis:\")\n",
    "        if critical_count > 0:\n",
    "            display(critical_alerts.select(\"claim_id\", \"enhanced_fraud_score\", \"alert_severity\", \"claim_amount\").limit(5))\n",
    "        else:\n",
    "            print(\"No critical alerts detected\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading critical alerts: {e}\")\n",
    "        critical_count = 0\n",
    "        critical_alerts = None\n",
    "    \n",
    "    try:\n",
    "        if ml_anomalies_exists:\n",
    "            ml_anomalies = spark.table(\"ml_anomalies_temp\")\n",
    "            ml_count = ml_anomalies.count()\n",
    "        else:\n",
    "            print(\"No ML anomalies found - creating empty dataframe\")\n",
    "            schema = StructType([\n",
    "                StructField(\"claim_id\", StringType(), True),\n",
    "                StructField(\"prediction\", IntegerType(), True),\n",
    "                StructField(\"claim_amount\", FloatType(), True),\n",
    "                StructField(\"fraud_risk_score\", FloatType(), True)\n",
    "            ])\n",
    "            ml_anomalies = spark.createDataFrame([], schema)\n",
    "            ml_count = 0\n",
    "        \n",
    "        print(f\"ML anomalies analysis:\")\n",
    "        if ml_count > 0:\n",
    "            display(ml_anomalies.select(\"claim_id\", \"prediction\", \"claim_amount\", \"fraud_risk_score\").limit(5))\n",
    "        else:\n",
    "            print(\"No ML anomalies detected\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading ML anomalies: {e}\")\n",
    "        ml_count = 0\n",
    "        ml_anomalies = None\n",
    "    \n",
    "    # =====================================================\n",
    "    # 3. Decision Logic with detailed analysis\n",
    "    # =====================================================\n",
    "    has_fraud = critical_count > 0 or ml_count > 0\n",
    "    \n",
    "    # Additional analysis for better decision context\n",
    "    high_confidence_fraud = critical_count > 0 and critical_count >= 3\n",
    "    ml_only_fraud = ml_count > 0 and critical_count == 0\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"FRAUD DECISION ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Critical Alerts Count: {critical_count}\")\n",
    "    print(f\"ML Anomalies Count: {ml_count}\")\n",
    "    print(f\"Any Fraud Detected: {has_fraud}\")\n",
    "    print(f\"High Confidence Fraud (3+ critical): {high_confidence_fraud}\")\n",
    "    print(f\"ML-Only Fraud Detection: {ml_only_fraud}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # =====================================================\n",
    "    # 4. Save decision as temporary view (not table)\n",
    "    # =====================================================\n",
    "    decision_schema = StructType([\n",
    "        StructField(\"has_fraud\", BooleanType(), True),\n",
    "        StructField(\"critical_count\", IntegerType(), True),\n",
    "        StructField(\"ml_count\", IntegerType(), True),\n",
    "        StructField(\"high_confidence\", BooleanType(), True),\n",
    "        StructField(\"ml_only\", BooleanType(), True),\n",
    "        StructField(\"total_alerts\", IntegerType(), True),\n",
    "        StructField(\"decision_timestamp\", TimestampType(), True),\n",
    "        StructField(\"routing_path\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    routing_path = \"FRAUD_DETECTED\" if has_fraud else \"NO_FRAUD\"\n",
    "    \n",
    "    decision_data = [(\n",
    "        has_fraud,\n",
    "        critical_count,\n",
    "        ml_count,\n",
    "        high_confidence_fraud,\n",
    "        ml_only_fraud,\n",
    "        critical_count + ml_count,\n",
    "        datetime.now(),\n",
    "        routing_path\n",
    "    )]\n",
    "    \n",
    "    decision_df = spark.createDataFrame(decision_data, decision_schema)\n",
    "    \n",
    "    # Save decision as temporary view for downstream tasks\n",
    "    decision_df.createOrReplaceTempView(\"fraud_decision_temp\")\n",
    "    print(\"✅ Decision saved as temporary view: fraud_decision_temp\")\n",
    "    \n",
    "    # =====================================================\n",
    "    # 5. Additional monitoring: Alert distribution\n",
    "    # =====================================================\n",
    "    try:\n",
    "        if critical_count > 0 and critical_alerts:\n",
    "            alert_distribution = critical_alerts.groupBy(\"alert_severity\") \\\n",
    "                .agg(\n",
    "                    lit(\"count\").alias(\"count\"),\n",
    "                    col(\"enhanced_fraud_score\").avg().alias(\"avg_score\"),\n",
    "                    col(\"claim_amount\").sum().alias(\"total_amount\")\n",
    "                )\n",
    "            \n",
    "            print(\"Alert severity distribution:\")\n",
    "            display(alert_distribution)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Alert distribution analysis skipped: {e}\")\n",
    "    \n",
    "    # =====================================================\n",
    "    # 6. Final summary and routing recommendation\n",
    "    # =====================================================\n",
    "    print(\"=\"*60)\n",
    "    print(\"ROUTING DECISION COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Fraud Detection Result: {'FRAUD DETECTED' if has_fraud else '✅ NO FRAUD'}\")\n",
    "    print(f\"Critical Alerts: {critical_count}\")\n",
    "    print(f\"ML Anomalies: {ml_count}\")\n",
    "    print(f\"Routing Path: {routing_path}\")\n",
    "    \n",
    "    if has_fraud:\n",
    "        print(\"Next: Proceed to alert generation and compliance reporting\")\n",
    "    else:\n",
    "        print(\"Next: Proceed to audit logging and clean transaction processing\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return has_fraud\n",
    "\n",
    "# Execute main function\n",
    "if __name__ == \"__main__\":\n",
    "    result = main()\n",
    "    dbutils.jobs.taskValues.set(\"has_fraud\", \"true\" if result else \"false\")\n",
    "    dbutils.notebook.exit(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af67cee8-f2df-4a24-8588-6f3febc88865",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_fraud_conditional_routing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
