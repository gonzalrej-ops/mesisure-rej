{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb4baaaf-2d27-425b-bdfc-7909e3717833",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#01_fraud_detection notebook\n",
    "# 03 - Fraud detection\n",
    "# **Purpose**: Monitor fraud patterns, generate alerts, and create compliance reports\n",
    "# **Schedule**: Run daily after Gold layer processing completes\n",
    "from pyspark.sql.functions import col, date_format, add_months, current_date\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "@udf(FloatType())\n",
    "def advanced_fraud_score(amount, diagnosis_code, provider_id, claim_frequency, member_risk_history):\n",
    "    score = 0.0\n",
    "    \n",
    "    # Amount-based scoring (progressive)\n",
    "    try:\n",
    "        amount_val = float(amount) if amount else 0\n",
    "        if amount_val > 50000: score += 0.4\n",
    "        elif amount_val > 25000: score += 0.3\n",
    "        elif amount_val > 10000: score += 0.2\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Diagnosis code patterns\n",
    "    suspicious_diagnoses = ['E119', 'I10', 'M545', 'R558', 'Z798']\n",
    "    if diagnosis_code in suspicious_diagnoses:\n",
    "        score += 0.2\n",
    "    \n",
    "    # Provider watchlist\n",
    "    high_risk_providers = ['PROV999', 'PROV888', 'PROV777']\n",
    "    if provider_id in high_risk_providers:\n",
    "        score += 0.3\n",
    "    \n",
    "    # Claim frequency\n",
    "    claim_freq = float(claim_frequency) if claim_frequency else 0\n",
    "    if claim_freq > 10:\n",
    "        score += 0.2\n",
    "    \n",
    "    # Member history\n",
    "    member_risk = float(member_risk_history) if member_risk_history else 0\n",
    "    if member_risk > 0.6:\n",
    "        score += 0.2\n",
    "    \n",
    "    return min(score, 1.0)\n",
    "\n",
    "def main():\n",
    "    # =====================================================\n",
    "    # 1. Read from Gold tables for monitoring\n",
    "    # =====================================================\n",
    "    print(\"Reading gold tables for fraud monitoring...\")\n",
    "    fraud_alerts = spark.table(\"medisure_jen.gold.gold_realtime_fraud_alerts\")\n",
    "    gold_claims = spark.table(\"medisure_jen.gold.gold_claims_analytics\")\n",
    "    provider_performance = spark.table(\"medisure_jen.gold.gold_provider_performance\")\n",
    "    member_summary = spark.table(\"medisure_jen.gold.gold_member_claims_summary\")\n",
    "    \n",
    "    # Display current day's fraud alerts for monitoring\n",
    "    print(\"Current fraud alerts:\")\n",
    "    display(spark.sql(\"\"\"\n",
    "    SELECT * FROM medisure_jen.gold.gold_realtime_fraud_alerts \n",
    "    ORDER BY alert_severity DESC, alert_timestamp DESC\n",
    "    LIMIT 20\n",
    "    \"\"\"))\n",
    "    \n",
    "    # =====================================================\n",
    "    # 1.2 Fraud Trends Analysis (Essential for monitoring)\n",
    "    # =====================================================\n",
    "    print(\"Analyzing fraud trends...\")\n",
    "    fraud_trends = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "      processing_month,\n",
    "      COUNT(*) as total_claims,\n",
    "      SUM(CASE WHEN fraud_risk_score > 0.7 THEN 1 ELSE 0 END) as high_risk_claims,\n",
    "      ROUND(AVG(fraud_risk_score), 3) as avg_fraud_score,\n",
    "      ROUND(SUM(CASE WHEN fraud_risk_score > 0.7 THEN claim_amount ELSE 0 END), 2) as high_risk_amount\n",
    "    FROM medisure_jen.gold.gold_claims_analytics\n",
    "    WHERE processing_month >= date_format(add_months(current_date(), -6), 'yyyy-MM')\n",
    "    GROUP BY processing_month\n",
    "    ORDER BY processing_month\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"Fraud trends analysis:\")\n",
    "    display(fraud_trends)\n",
    "    \n",
    "    # =====================================================\n",
    "    # 2. Read additional tables for fraud detection\n",
    "    # =====================================================\n",
    "    print(\"Reading additional tables for enhanced fraud detection...\")\n",
    "    members = spark.table(\"medisure_jen.silver.silver_members\")\n",
    "    providers = spark.table(\"medisure_jen.silver.silver_providers\")\n",
    "    member_summary = spark.table(\"medisure_jen.gold.gold_member_claims_summary\")\n",
    "    \n",
    "    # =====================================================\n",
    "    # 3. Apply fraud scoring (detection part)\n",
    "    # =====================================================\n",
    "    print(\"Applying enhanced fraud scoring...\")\n",
    "    alerts_with_enhanced_scoring = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "      a.claim_id, a.member_id, a.provider_id, a.claim_amount,\n",
    "      a.diagnosis_code, a.alert_severity, a.alert_reason, a.alert_timestamp,\n",
    "      split(m.member_name, ' ')[0] as first_name,\n",
    "      array_join(slice(split(m.member_name, ' '), 2, size(split(m.member_name, ' ')) - 1), ' ') as last_name,\n",
    "      p.provider_name,\n",
    "      mem.claims_count as member_claim_frequency,\n",
    "      mem.member_risk_score as member_risk_history\n",
    "    FROM medisure_jen.gold.gold_realtime_fraud_alerts a\n",
    "    LEFT JOIN medisure_jen.silver.silver_members m ON a.member_id = m.member_id\n",
    "    LEFT JOIN medisure_jen.silver.silver_providers p ON a.provider_id = p.provider_id\n",
    "    LEFT JOIN medisure_jen.gold.gold_member_claims_summary mem ON a.member_id = mem.member_id \n",
    "      AND mem.summary_period = date_format(current_date(), 'yyyy-MM-dd')\n",
    "    WHERE a.alert_severity IN ('Critical', 'High')\n",
    "      AND date(a.alert_timestamp) >= date_add(current_date(), -7)\n",
    "    \"\"\")\n",
    "    \n",
    "    spark.udf.register(\"advanced_fraud_score\", advanced_fraud_score)\n",
    "    critical_alerts = alerts_with_enhanced_scoring.withColumn(\n",
    "        \"enhanced_fraud_score\", \n",
    "        advanced_fraud_score(\n",
    "            col(\"claim_amount\"), \n",
    "            col(\"diagnosis_code\"), \n",
    "            col(\"provider_id\"),\n",
    "            col(\"member_claim_frequency\"),\n",
    "            col(\"member_risk_history\")\n",
    "        )\n",
    "    ).filter(col(\"enhanced_fraud_score\") >= 0.5).orderBy(col(\"claim_amount\").desc())\n",
    "\n",
    "    \n",
    "    # =====================================================\n",
    "    # 4. Save results for next tasks\n",
    "    # =====================================================\n",
    "    critical_alerts.createOrReplaceTempView(\"critical_alerts\")\n",
    "    display(critical_alerts)\n",
    "    \n",
    "    # =====================================================\n",
    "    # 5. Return simple count for routing + monitoring info\n",
    "    # =====================================================\n",
    "    fraud_count = critical_alerts.count()\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"FRAUD DETECTION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Critical Alerts Detected: {fraud_count}\")\n",
    "    print(f\"Total Fraud Alerts Today: {fraud_alerts.count()}\")\n",
    "    print(f\"High Risk Claims (Trends): {fraud_trends.filter(col('processing_month') == date_format(current_date(), 'yyyy-MM')).select('high_risk_claims').first()[0] if fraud_trends.count() > 0 else 'N/A'}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return fraud_count\n",
    "\n",
    "# Execute main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_fraud_detection",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
